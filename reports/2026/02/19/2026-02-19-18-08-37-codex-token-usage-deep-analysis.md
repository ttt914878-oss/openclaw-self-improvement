# Codex Token Usage Deep Analysis (2026-02-19)

## 0) 対象・前提
- 対象ログ:
  - `/home/ttt05/.openclaw/agents/main/sessions/*.jsonl`（JST 2026-02-19に該当するassistant message）
  - `/home/ttt05/.openclaw/workspace/reports/2026/02/19/*`
- 解析母数:
  - assistant message: **1,014件**
  - totalTokens合計: **81,022,566**
- モデル内訳:
  - `gpt-5.3-codex`: **80,998,250 tokens（99.97%）**
  - `gemini-3-flash-preview`: 24,316 tokens（0.03%）
- 参考: レポートファイル数は **100件**（うち `now-*` 31件、`pdca*` 13件、`research*` 14件）

---

## 1) 消費内訳（推定分類）
分類は「直前user指示 + assistant内容/stopReason」のヒューリスティック判定。

| 区分 | Tokens | 構成比 |
|---|---:|---:|
| 報告文生成 | 68,079,536 | **84.02%** |
| 実作業 | 8,054,532 | 9.94% |
| ルール更新 | 418,532 | 0.52% |
| 失敗リトライ | 0 | 0.00% |
| その他 | 4,469,966 | 5.52% |
| **合計** | **81,022,566** | **100%** |

### 追加観測
- token構成（全体）
  - input: 21,858,777
  - output: 204,173
  - **cacheRead: 58,959,616（全体の72.77%）**
- 1ターンあたり平均: 約79,904 tokens
- 高消費の主因は「出力の長文化」より、**巨大コンテキスト再読込（input+cacheRead）**

---

## 2) 「報告」が総消費の何%か（推定レンジ）
- 推定中心値: **84.02%**
- 推定レンジ: **78%〜88%**

### 根拠
1. 5分/15分cron系（backlog実行・PDCAレビュー）と`now-*`,`pdca*`レポート作成が大量反復。
2. 上位プロンプト群が「定期報告/進捗整形」系で占有。
3. 最大消費ターンは実装よりも、報告サイクル中の`toolUse`で発生（1ターン19万token級）。

---

## 3) 無駄消費トップ5（具体例）

## 1) 5分バックログ実行ループ（cron）
- 集計（同系プロンプト群）:
  - 19,655,205
  - 7,944,930
  - 6,353,704
- 合計で少なくとも **33.95M+ tokens**。
- 同一意図の高頻度反復で、毎回巨大文脈を再読込。

## 2) 15分PDCAレビューの定期重複
- 代表群: **2,121,631 tokens**（単一プロンプト群）
- レビュー自体は必要だが、頻度とテンプレ長が過剰。

## 3) チャットメタ付き会話起点での再読込
- `Conversation info (untrusted metadata)`起点の上位群:
  - 1,840,905
  - 1,814,954
  - 1,149,733
  - 1,117,306
- 実行前の文脈肥大に寄与。

## 4) 大型コンテキストでの軽作業（commit/report）
- 例: `2026-02-19T09:05:11.819Z`
  - totalTokens: **197,605**
  - input: 114,026 / cacheRead: 83,456 / output: 123
- 小さな操作（git add/commit）に対して入力量が極端に大きい。

## 5) レポートファイル大量生成（100件/日）
- `now-*` 31件、`pdca*` 13件。
- 1件は短文でも、生成までの毎ターンで大文脈を読むため累積が肥大。

---

## 4) 100%段階から有効な省トークン運用設計（即適用版）

## Phase A: Usage 100%→80%（予防フェーズ）
1. **定期実行間隔の即時変更**
   - backlog実行: 5分→**15分**
   - PDCAレビュー: 15分→**30〜60分**
2. **報告テンプレを3行固定**
   - 「実施1件 / KPI差分 / 次アクション1件」のみ。
3. **報告と実作業を分離**
   - 実作業セッションではレポート生成禁止（最後に1回だけ）。

## Phase B: Usage 80%→60%（最適化フェーズ）
1. **コンテキスト予算制御（hard cap）**
   - `totalTokens > 120k/turn`を検知したら強制簡略モード。
2. **巨大ファイル参照の局所化**
   - `read`はoffset/limit必須化、全文読込禁止。
3. **同型タスクのバッチ化**
   - `now-*`系を都度生成せず、30分ごとに1ファイルへ集約。

## Phase C: Usage 60%→40%（防衛フェーズ）
1. **モデルルーティング**
   - 報告/整形は軽量モデル、重推論のみ高性能モデル。
2. **ルール更新タスクの窓口一本化**
   - ルール変更は1日2回の窓でまとめる。
3. **失敗時の再試行上限**
   - 同一失敗3回で停止して人手確認。

## Phase D: Usage 40%以下（緊急節約）
1. cronの非必須ジョブ停止（報告系優先停止）
2. 出力フォーマットを箇条書き5行上限
3. 新規調査を凍結し、既存知見再利用のみ

---

## 5) すぐ実施すべき設定変更（本日版）
1. cron設定: backlog 15分、PDCA 30分へ変更
2. report生成ルール: 1サイクル1ファイル禁止、30分1ファイル集約
3. turn token guard: 120k超で自動`compact + short mode`
4. 作業系タスクでは`report`語を禁止語にして実作業完了後のみ報告
5. 日次KPI: `report_token_share <= 35%` を運用SLO化

---

## 6) チャット/cron由来の比率（参考）
- cron起点: **45,390,851 tokens（56.02%）**
- チャット起点: 35,631,715 tokens（43.98%）
- 過大消費の中心は **cron高頻度ループ**。

---

## 7) モデル方針実行結果
- 指示に従い `gemini -m gemini-3-pro-preview` を先行試行 → CLI待機状態でtimeout。
- フォールバック `gemini -m gemini-3-flash-preview` も同様にtimeout。
- そのため本レポートはローカルログ直接解析で作成。

---

## 結論（要点）
- 本日の過大消費は、実作業ではなく**報告ループの高頻度反復**が主要因。
- 消費の実体は出力量ではなく、**巨大コンテキスト再読込（cacheRead主導）**。
- 最優先は「頻度削減」「報告集約」「turn上限ガード」の3点。これで即日で大幅圧縮可能。